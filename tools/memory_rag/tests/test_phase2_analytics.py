"""
Tests for MBIE Phase 2 analytics and learning functionality.

Tests query pattern tracking, analytics collection, pattern analysis,
and navigation optimization features.

@see memory-bank/features/mbie-intelligence/phase2-design.md#analytics-data-models
@navigation Use startHere.md â†’ "ðŸ§  Memory-Bank Intelligence Engine (MBIE)" path for context
"""

import pytest
import tempfile
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
import json

from core.analytics import (
    AnalyticsDatabase, AnalyticsCollector, PatternAnalyzer,
    QueryAnalytics, UserInteraction, NavigationPattern,
    create_analytics_system
)
from core.learning import (
    NavigationOptimizer, SuggestionEngine, AdaptiveLearningEngine,
    BusinessContext, ContentSuggestion, NavigationOptimization,
    create_learning_engine
)


# Global fixtures available to all test classes
@pytest.fixture
def sample_analytics():
    """Create sample analytics data for pattern analysis"""
    analytics_list = []
    
    # Create similar queries with successful interactions
    for i in range(5):
        interaction = UserInteraction(
            clicked_results=[f"chunk_{i}", f"chunk_{i+1}"],
            time_spent=30 + i * 10,  # Varying engagement times
            follow_up_queries=[],
            satisfaction_score=0.6 + i * 0.08,  # Increasing satisfaction
            interaction_type="click"
        )
        
        analytics = QueryAnalytics(
            query_id=f"andrew_query_{i}",
            query_text=f"andrew client focus {i}",
            timestamp=datetime.now() - timedelta(days=i),
            user_session=f"session_{i % 2}",  # Two different sessions
            search_results=[f"chunk_{i}", f"chunk_{i+1}"],
            user_interaction=interaction,
            business_context="Q3 2025 Foundation Quarter" if i % 2 == 0 else "Automation Management",
            response_time_ms=100.0,
            result_count=1
        )
        analytics_list.append(analytics)
        
    return analytics_list


@pytest.fixture  
def sample_patterns():
    """Create sample navigation patterns"""
    return [
        NavigationPattern(
            pattern_id="pattern_1",
            query_pattern=r".*andrew.*client.*",
            recommended_content=["activeContext.md", "client-engagement.md"],
            frequency=8,
            confidence=0.85,
            business_context="Q3 2025 Foundation Quarter",
            success_rate=0.9,
            last_updated=datetime.now() - timedelta(days=1)
        ),
        NavigationPattern(
            pattern_id="pattern_2", 
            query_pattern=r".*automation.*workflow.*",
            recommended_content=["systemPatterns.md", "automation-suite.md"],
            frequency=5,
            confidence=0.7,
            business_context="Automation Management",
            success_rate=0.6,
            last_updated=datetime.now()
        )
    ]


class TestAnalyticsDatabase:
    """Test analytics database operations"""
    
    @pytest.fixture
    def temp_db(self):
        """Create temporary database for testing"""
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as f:
            db_path = f.name
        db = AnalyticsDatabase(db_path)
        yield db
        Path(db_path).unlink()
        
    def test_database_initialization(self, temp_db):
        """Test database schema creation"""
        # Verify tables exist
        with sqlite3.connect(temp_db.db_path) as conn:
            cursor = conn.execute(
                "SELECT name FROM sqlite_master WHERE type='table'"
            )
            tables = [row[0] for row in cursor.fetchall()]
            
        expected_tables = [
            'query_analytics', 'user_interactions', 
            'navigation_patterns', 'usage_sessions'
        ]
        for table in expected_tables:
            assert table in tables
            
    def test_store_query_analytics(self, temp_db):
        """Test storing query analytics data"""
        analytics = QueryAnalytics(
            query_id="test_query_1",
            query_text="current focus andrew client",
            timestamp=datetime.now(),
            user_session="session_1",
            search_results=["chunk1", "chunk2"],
            user_interaction=None,
            business_context="Q3 2025 Foundation Quarter",
            response_time_ms=150.5,
            result_count=2
        )
        
        temp_db.store_query_analytics(analytics)
        
        # Verify data was stored
        retrieved = temp_db.get_query_analytics(days_back=1)
        assert len(retrieved) == 1
        assert retrieved[0].query_text == "current focus andrew client"
        assert retrieved[0].result_count == 2
        
    def test_store_with_interaction(self, temp_db):
        """Test storing analytics with user interaction"""
        interaction = UserInteraction(
            clicked_results=["chunk1"],
            time_spent=45,
            follow_up_queries=["andrew sprint preparation"],
            satisfaction_score=0.8,
            interaction_type="click"
        )
        
        analytics = QueryAnalytics(
            query_id="test_query_2",
            query_text="test query with interaction",
            timestamp=datetime.now(),
            user_session="session_2",
            search_results=["chunk1", "chunk2", "chunk3"],
            user_interaction=interaction,
            business_context="Test Context",
            response_time_ms=200.0,
            result_count=3
        )
        
        temp_db.store_query_analytics(analytics)
        
        # Verify interaction was stored
        retrieved = temp_db.get_query_analytics(days_back=1)
        assert len(retrieved) == 1
        assert retrieved[0].user_interaction is not None
        assert retrieved[0].user_interaction.satisfaction_score == 0.8
        assert retrieved[0].user_interaction.time_spent == 45
        
    def test_store_navigation_pattern(self, temp_db):
        """Test storing navigation patterns"""
        pattern = NavigationPattern(
            pattern_id="pattern_test_1",
            query_pattern=r".*andrew.*client.*",
            recommended_content=["chunk1", "chunk2"],
            frequency=5,
            confidence=0.8,
            business_context="Q3 2025 Foundation Quarter",
            success_rate=0.7,
            last_updated=datetime.now()
        )
        
        temp_db.store_navigation_pattern(pattern)
        
        # Verify pattern was stored
        patterns = temp_db.get_navigation_patterns()
        assert len(patterns) == 1
        assert patterns[0].query_pattern == r".*andrew.*client.*"
        assert patterns[0].frequency == 5
        
    def test_filter_by_business_context(self, temp_db):
        """Test filtering analytics by business context"""
        # Store analytics with different contexts
        contexts = ["Q3 2025", "Q4 2025", "Q3 2025"]
        for i, context in enumerate(contexts):
            analytics = QueryAnalytics(
                query_id=f"query_{i}",
                query_text=f"query {i}",
                timestamp=datetime.now(),
                user_session=f"session_{i}",
                search_results=[],
                user_interaction=None,
                business_context=context,
                response_time_ms=100.0,
                result_count=0
            )
            temp_db.store_query_analytics(analytics)
            
        # Filter by specific context
        q3_analytics = temp_db.get_query_analytics(
            days_back=1, business_context="Q3 2025"
        )
        assert len(q3_analytics) == 2
        
        all_analytics = temp_db.get_query_analytics(days_back=1)
        assert len(all_analytics) == 3


class TestPatternAnalyzer:
    """Test pattern analysis functionality"""
    
    @pytest.fixture
    def analyzer(self):
        """Create pattern analyzer for testing"""
        config = {
            'analytics': {
                'pattern_analysis': {
                    'min_pattern_frequency': 2,
                    'confidence_threshold': 0.6,
                    'learning_window_days': 14,
                    'success_thresholds': {
                        'min_time_spent': 25,  # Lower threshold for tests
                        'min_satisfaction_score': 0.6,  # Lower threshold for tests
                        'min_success_rate': 0.4,  # Lower threshold for tests
                        'min_engagement_time': 15  # Lower threshold for tests
                    },
                    'context_confidence_threshold': 0.5  # Lower threshold for tests
                }
            }
        }
        return PatternAnalyzer(config)
        
        
    def test_query_clustering(self, analyzer, sample_analytics):
        """Test semantic query clustering"""
        # Test the clustering step directly since analyze_query_patterns is complex
        clusters = analyzer._cluster_queries_semantically(sample_analytics)
        
        # Should cluster the similar queries together
        assert len(clusters) >= 1
        assert 'andrew_client_focus' in clusters
        assert len(clusters['andrew_client_focus']) == 5  # All 5 queries should cluster together
        
        # Check cluster contains the expected queries
        cluster_queries = clusters['andrew_client_focus']
        query_texts = [q.query_text for q in cluster_queries]
        assert all('andrew client focus' in text for text in query_texts)
            
    def test_pattern_confidence_calculation(self, analyzer, sample_analytics):
        """Test confidence calculation for discovered patterns"""
        patterns = analyzer.analyze_query_patterns(sample_analytics)
        
        # Find andrew-related pattern
        andrew_patterns = [p for p in patterns if "andrew" in p.query_pattern.lower()]
        
        if andrew_patterns:
            pattern = andrew_patterns[0]
            # Should have high confidence due to consistent successful interactions
            assert pattern.confidence >= 0.6
            assert pattern.success_rate >= 0.6
            
    def test_business_context_correlation(self, analyzer, sample_analytics):
        """Test business context correlation in patterns"""
        # Test the business context correlation step directly
        clusters = analyzer._cluster_queries_semantically(sample_analytics)
        successful_patterns = analyzer._find_high_engagement_patterns(clusters)
        
        # Should find high engagement patterns
        assert len(successful_patterns) >= 0  # May or may not find patterns based on thresholds
        
        # Test business context distribution
        context_distribution = {}
        for analytics in sample_analytics:
            context = analytics.business_context
            context_distribution[context] = context_distribution.get(context, 0) + 1
        
        # Should have the expected business contexts
        assert "Q3 2025 Foundation Quarter" in context_distribution
        assert "Automation Management" in context_distribution
        assert context_distribution["Q3 2025 Foundation Quarter"] == 3
        assert context_distribution["Automation Management"] == 2
        
        
class TestNavigationOptimizer:
    """Test navigation optimization functionality"""
    
    @pytest.fixture
    def optimizer(self):
        """Create navigation optimizer for testing"""
        config = {
            'learning': {
                'adaptation_rate': 0.1,
                'update_threshold': 3
            }
        }
        with tempfile.TemporaryDirectory() as temp_dir:
            return NavigationOptimizer(config, temp_dir)
            
        
    def test_path_usage_analysis(self, optimizer, sample_analytics, sample_patterns):
        """Test analysis of navigation path usage patterns"""
        optimizations = optimizer.analyze_navigation_efficiency(
            sample_analytics, sample_patterns
        )
        
        # Should generate some optimization recommendations
        assert isinstance(optimizations, list)
        
        # Check optimization structure
        for opt in optimizations:
            assert hasattr(opt, 'optimization_id')
            assert hasattr(opt, 'improvement_type')
            assert hasattr(opt, 'confidence')
            assert opt.confidence >= 0.0 and opt.confidence <= 1.0
            
    def test_pattern_efficiency_analysis(self, optimizer, sample_patterns):
        """Test pattern efficiency analysis"""
        # Create patterns with varying efficiency
        efficient_patterns = [
            NavigationPattern(
                pattern_id="efficient_1",
                query_pattern=r".*high.*success.*",
                recommended_content=["chunk1"],
                frequency=8,
                confidence=0.9,
                business_context="Test Context",
                success_rate=0.9,
                last_updated=datetime.now()
            ),
            NavigationPattern(
                pattern_id="efficient_2",
                query_pattern=r".*another.*high.*",
                recommended_content=["chunk2"],
                frequency=6,
                confidence=0.8,
                business_context="Test Context",
                success_rate=0.85,
                last_updated=datetime.now()
            )
        ]
        
        optimizations = optimizer._analyze_pattern_efficiency(efficient_patterns)
        
        # Should identify high-performing patterns for prioritization
        if optimizations:
            assert any(opt.improvement_type == "reorder" for opt in optimizations)


class TestSuggestionEngine:
    """Test contextual suggestion generation"""
    
    @pytest.fixture
    def suggestion_engine(self):
        """Create suggestion engine for testing"""
        config = {
            'learning': {
                'prediction_window_days': 3,
                'confidence_threshold': 0.7
            }
        }
        with tempfile.TemporaryDirectory() as temp_dir:
            return SuggestionEngine(config, temp_dir)
            
    @pytest.fixture
    def business_context(self):
        """Create sample business context"""
        return BusinessContext(
            current_phase="Q3 2025 Foundation Quarter",
            current_week="Week 3",
            active_client="Example Client",
            upcoming_events=["Sprint Aug 20-22"],
            focus_areas=["Pre-Sprint Preparation"],
            energy_level="high",
            time_context="morning"
        )
        
    def test_context_based_suggestions(self, suggestion_engine, business_context, sample_patterns):
        """Test generation of context-based suggestions"""
        suggestions = suggestion_engine._generate_context_suggestions(
            business_context, sample_patterns
        )
        
        # Should generate relevant suggestions
        assert isinstance(suggestions, list)
        
        for suggestion in suggestions:
            assert isinstance(suggestion, ContentSuggestion)
            assert suggestion.confidence >= 0.0 and suggestion.confidence <= 1.0
            assert suggestion.relevance_score >= 0.0 and suggestion.relevance_score <= 1.0
            
    def test_time_based_suggestions(self, suggestion_engine, business_context):
        """Test time-based suggestion generation"""
        suggestions = suggestion_engine._generate_time_based_suggestions(business_context)
        
        # Should generate suggestions based on upcoming events
        assert isinstance(suggestions, list)
        
        # Check for sprint-related suggestions
        sprint_suggestions = [s for s in suggestions if "sprint" in s.title.lower()]
        if sprint_suggestions:
            assert any(s.urgency == "high" for s in sprint_suggestions)
            
    def test_predictive_suggestions(self, suggestion_engine, business_context):
        """Test predictive suggestion generation"""
        suggestions = suggestion_engine._generate_predictive_suggestions(business_context)
        
        # Should generate predictions based on business cycle
        assert isinstance(suggestions, list)
        
        # Verify prediction quality - should have valid suggestion objects
        for suggestion in suggestions:
            assert hasattr(suggestion, 'context_match')
            assert hasattr(suggestion, 'confidence')
            assert suggestion.confidence >= 0.0 and suggestion.confidence <= 1.0
                   
    def test_suggestion_filtering_and_ranking(self, suggestion_engine):
        """Test suggestion filtering and ranking"""
        # Create test suggestions with different scores
        test_suggestions = [
            ContentSuggestion(
                content_id="high_relevance",
                title="High Relevance Content",
                navigation_path="test/path",
                relevance_score=0.9,
                confidence=0.8,
                reason="Test reason",
                context_match="Test",
                urgency="high"
            ),
            ContentSuggestion(
                content_id="low_confidence",
                title="Low Confidence Content", 
                navigation_path="test/path2",
                relevance_score=0.8,
                confidence=0.5,  # Below threshold
                reason="Test reason",
                context_match="Test",
                urgency="medium"
            ),
            ContentSuggestion(
                content_id="duplicate",
                title="Duplicate Content",
                navigation_path="test/path3",
                relevance_score=0.7,
                confidence=0.8,
                reason="Test reason",
                context_match="Test",
                urgency="low"
            ),
            ContentSuggestion(
                content_id="duplicate",  # Same content_id
                title="Duplicate Content Better",
                navigation_path="test/path4",
                relevance_score=0.85,  # Higher score
                confidence=0.9,
                reason="Test reason",
                context_match="Test",
                urgency="medium"
            )
        ]
        
        filtered = suggestion_engine._filter_and_rank_suggestions(test_suggestions)
        
        # Should filter low confidence and deduplicate
        assert len(filtered) <= 3
        
        # Should keep higher scoring duplicate
        content_ids = [s.content_id for s in filtered]
        if "duplicate" in content_ids:
            duplicate_suggestion = next(s for s in filtered if s.content_id == "duplicate")
            assert duplicate_suggestion.relevance_score == 0.85
            
        # Should be sorted by combined score
        if len(filtered) > 1:
            for i in range(len(filtered) - 1):
                assert filtered[i].combined_score >= filtered[i + 1].combined_score


class TestAdaptiveLearningEngine:
    """Test complete adaptive learning engine"""
    
    @pytest.fixture
    def learning_engine(self):
        """Create learning engine for testing"""
        config = {
            'learning': {'enabled': True},
            'analytics': {'enabled': True},
            'storage': {'analytics_path': ':memory:'}
        }
        with tempfile.TemporaryDirectory() as temp_dir:
            return create_learning_engine(config, temp_dir)
            
    @pytest.fixture
    def analytics_system(self):
        """Create analytics system for testing"""
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as f:
            db_path = f.name
        
        config = {
            'analytics': {'database_path': db_path},
            'storage': {'analytics_path': db_path}
        }
        
        try:
            collector, analyzer = create_analytics_system(config)
            yield collector, analyzer
        finally:
            Path(db_path).unlink(missing_ok=True)
        
    def test_business_context_extraction(self, learning_engine):
        """Test extraction of current business context"""
        context = learning_engine.get_current_business_context()
        
        # Should return valid business context
        assert isinstance(context, BusinessContext)
        assert context.current_phase is not None
        assert context.current_week is not None
        assert context.time_context in ["morning", "afternoon", "evening"]
        
    def test_learning_cycle_execution(self, learning_engine, analytics_system):
        """Test complete learning cycle execution"""
        collector, analyzer = analytics_system
        
        # Add some sample data
        session_id = collector.start_session("test_session")
        query_id = collector.record_query(
            query_text="andrew client sprint preparation",
            search_results=["chunk1", "chunk2"],
            response_time_ms=150.0,
            business_context="Q3 2025 Foundation Quarter"
        )
        collector.record_interaction(
            query_id=query_id,
            interaction_type="click",
            clicked_results=["chunk1"],
            time_spent=60,
            satisfaction_score=0.8
        )
        collector.end_session()
        
        # Run learning cycle
        context = learning_engine.get_current_business_context()
        results = learning_engine.run_learning_cycle(collector, analyzer, context)
        
        # Should complete successfully
        assert results['status'] == 'success'
        assert 'analytics_summary' in results
        assert 'optimizations' in results
        assert 'suggestions' in results
        
    def test_learning_disabled(self):
        """Test behavior when learning is disabled"""
        config = {'learning': {'enabled': False}}
        with tempfile.TemporaryDirectory() as temp_dir:
            engine = AdaptiveLearningEngine(config, temp_dir)
            
            collector, analyzer = create_analytics_system(config)
            context = engine.get_current_business_context()
            
            results = engine.run_learning_cycle(collector, analyzer, context)
            assert results['status'] == 'learning_disabled'


# Integration tests
class TestPhase2Integration:
    """Integration tests for Phase 2 components"""
    
    def test_analytics_to_learning_pipeline(self):
        """Test full pipeline from analytics collection to learning optimization"""
        # Create temporary systems
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as f:
            db_path = f.name
            
        config = {
            'analytics': {
                'enabled': True,
                'database_path': db_path,
                'min_pattern_frequency': 2,
                'confidence_threshold': 0.6
            },
            'learning': {'enabled': True}
        }
        
        try:
            with tempfile.TemporaryDirectory() as temp_dir:
                # Create systems
                collector, analyzer = create_analytics_system(config)
                learning_engine = create_learning_engine(config, temp_dir)
            
                # Simulate usage pattern
                session_id = collector.start_session("integration_test")
                
                # Record several similar queries
                for i in range(3):
                    query_id = collector.record_query(
                        query_text=f"andrew client focus meeting {i}",
                        search_results=["andrew_chunk", "client_chunk", "focus_chunk"],
                        response_time_ms=120.0 + i * 10,
                        business_context="Q3 2025 Foundation Quarter"
                    )
                    
                    collector.record_interaction(
                        query_id=query_id,
                        interaction_type="click",
                        clicked_results=["andrew_chunk", "client_chunk"],
                        time_spent=45 + i * 5,
                        satisfaction_score=0.7 + i * 0.1
                    )
                    
                collector.end_session()
                
                # Run learning cycle
                context = learning_engine.get_current_business_context()
                results = learning_engine.run_learning_cycle(collector, analyzer, context)
                
                # Verify pipeline worked
                assert results['status'] == 'success'
                assert results['analytics_summary']['total_queries'] == 3
                
                # Should discover patterns from similar queries
                patterns_discovered = results.get('patterns_discovered', [])
                if patterns_discovered:
                    assert any('andrew' in p['pattern'].lower() for p in patterns_discovered)
                    
                # Should generate relevant suggestions
                suggestions = results.get('suggestions', [])
                assert isinstance(suggestions, list)
        finally:
            Path(db_path).unlink(missing_ok=True)
            
    def test_error_handling(self):
        """Test error handling in Phase 2 components"""
        # Test with invalid config that will cause filesystem errors
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as temp_file:
            invalid_db_path = temp_file.name + '/invalid/path/db.sqlite'  # This will fail
        
        invalid_config = {'analytics': {'database_path': invalid_db_path}}
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # Should raise an exception during creation
            with pytest.raises((OSError, FileNotFoundError)):
                collector, analyzer = create_analytics_system(invalid_config)


if __name__ == "__main__":
    # Run basic functionality tests
    print("Running Phase 2 Analytics Tests...")
    
    # Test database creation
    with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as f:
        db_path = f.name
        
    try:
        db = AnalyticsDatabase(db_path)
        print("âœ… Database initialization successful")
        
        # Test analytics storage
        analytics = QueryAnalytics(
            query_id="test_1",
            query_text="test query",
            timestamp=datetime.now(),
            user_session="session_1",
            search_results=["chunk1"],
            user_interaction=None,
            business_context="Test",
            response_time_ms=100.0,
            result_count=1
        )
        db.store_query_analytics(analytics)
        
        retrieved = db.get_query_analytics(days_back=1)
        assert len(retrieved) == 1
        print("âœ… Analytics storage and retrieval successful")
        
        # Test pattern analysis
        config = {'analytics': {'min_pattern_frequency': 1, 'confidence_threshold': 0.5}}
        analyzer = PatternAnalyzer(config)
        patterns = analyzer.analyze_query_patterns(retrieved)
        print(f"âœ… Pattern analysis successful, discovered {len(patterns)} patterns")
        
        print("\nðŸŽ‰ All Phase 2 Analytics tests passed!")
        
    finally:
        Path(db_path).unlink(missing_ok=True)